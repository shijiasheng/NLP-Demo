Add tests for target
Add tests for global targets
Add examples of specific documents to 20ng example
Add better naming to categorical variables, e.g. like target variables
Keep track of doc counts between model serializations
Add bigramming
Add better README
Add an example script with HN with doc id, client id, and predicted score
Add super simple explanatory models
Remove spacy dep
Change EmbedMixture naming to possible values and n latent factors
Print out topics while training
Add doctets to lda2vec main classes
Randomize chunking order on fit
Add loss tracking and reporting classes to code
Finish filling out docstrings
Add multiple targets for one component
Add convergence criterion

Add docs on:
    Installation
    HN Tutorial
        Parse document into vector
        Setup LDA for document
        Mesure perplexity
        Visualize topics
        Add supervised component
        Mesure perplexity
        Visualize topics
        Add another component for time
        Mesure perplexity
        Visualize topics
        Visualize topics, changing temperature
    Data formats
        Loose
        Compact
        Flat
    Contexts
        Categorical contexts
        Other contexts TBA
    Targets
        RMSE
        Logistic
        Softmax
    Advanced
        Options
            GPU
            Gradient Clipping
            Online learning, fraction argument
        Logging progress
        Perplexity
        Model saving, prediction
        Dropout fractions

Nomenclature
    Categorical Feature
        Each category in set has n_possible_values
        Each feature has n_latent_factors
        Each feature has a single target
    Components
        Each component defined total number of documents and number of topics
        Each component may also have supervised targets

Done:
    Add BoW mode
    Add logger
    Add fake data generator
    Add perplexity measurements
    Add tracking utility
    Add utilities for converting corpora
    Put license
    Add masks / skips / pads
    Add reindexing on the fly
    Convert docstrings to numpy format
    Implement corpus loose to dense and vice versa
    Add fit function for all data at once
    Add CI & coverage & license icons
    Add readthedocs support
    Add examples to CI
    Add dropout
    Change component naming to 'categorical feature'
    Add linear layers between input latent and output context
    Merge skipgram branch
    Add topic numbers to topic print out
    Try higher importance to the prior
    Change prob model to just model prob of word in topic
    Add word dropout
    Add an example script with 20 newsgroups -- LDA
    Add visualization for topic-word
    Implement skipgram contexts
    Prevent mixing between documents
    Add temperature to perplexity measurements
    Add temperature to viz
    Add model saving
    Add model predicting
    Hook up RTD to docstrings
